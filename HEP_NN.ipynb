{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HEP.NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtvvfn5yrKVBgcHM7M5rOl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sainikithaharish06/NN.Hep.Class/blob/main/HEP_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IOsRYNhb3Cb-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "null_values=[\"?\",]"
      ],
      "metadata": {
        "id": "sOqj4FUD5uDx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hp=pd.read_csv(\"hepatitis dataset.csv\",index_col=False,na_values=null_values,\n",
        "                    names=[\"CLASS\",\"AGE\",\"SEX\",\"SETROID\",\"ANTIVIRAL\",\"FATIGUE\",\"MALASIA\",\"ANOREXIA\",\"LIVER BIG\",\"LIVER FIRM\",\n",
        "                                                   \"SPLEEN PALPABLE\",\"SPIDERS\",\"ASCITES\",\"VARICES\",\"BILIRUBIN\",\"ALK PHOSPHATE\",\"SGOT\",\"ALBUMIN\",\n",
        "                                                   \"PROTIME\",\"HISTOLOGY\"])\n",
        "Hp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "DUbLxnlP5bDk",
        "outputId": "23e48590-25fb-40a6-f527-6adb8ac8743b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     CLASS  AGE  SEX  SETROID  ANTIVIRAL  FATIGUE  MALASIA  ANOREXIA  \\\n",
              "0        2   30    2      1.0          2      2.0      2.0       2.0   \n",
              "1        2   50    1      1.0          2      1.0      2.0       2.0   \n",
              "2        2   78    1      2.0          2      1.0      2.0       2.0   \n",
              "3        2   31    1      NaN          1      2.0      2.0       2.0   \n",
              "4        2   34    1      2.0          2      2.0      2.0       2.0   \n",
              "..     ...  ...  ...      ...        ...      ...      ...       ...   \n",
              "150      1   46    1      2.0          2      1.0      1.0       1.0   \n",
              "151      2   44    1      2.0          2      1.0      2.0       2.0   \n",
              "152      2   61    1      1.0          2      1.0      1.0       2.0   \n",
              "153      2   53    2      1.0          2      1.0      2.0       2.0   \n",
              "154      1   43    1      2.0          2      1.0      2.0       2.0   \n",
              "\n",
              "     LIVER BIG  LIVER FIRM  SPLEEN PALPABLE  SPIDERS  ASCITES  VARICES  \\\n",
              "0          1.0         2.0              2.0      2.0      2.0      2.0   \n",
              "1          1.0         2.0              2.0      2.0      2.0      2.0   \n",
              "2          2.0         2.0              2.0      2.0      2.0      2.0   \n",
              "3          2.0         2.0              2.0      2.0      2.0      2.0   \n",
              "4          2.0         2.0              2.0      2.0      2.0      2.0   \n",
              "..         ...         ...              ...      ...      ...      ...   \n",
              "150        2.0         2.0              2.0      1.0      1.0      1.0   \n",
              "151        2.0         1.0              2.0      2.0      2.0      2.0   \n",
              "152        1.0         1.0              2.0      1.0      2.0      2.0   \n",
              "153        2.0         2.0              1.0      1.0      2.0      1.0   \n",
              "154        2.0         2.0              1.0      1.0      1.0      2.0   \n",
              "\n",
              "     BILIRUBIN  ALK PHOSPHATE   SGOT  ALBUMIN  PROTIME  HISTOLOGY  \n",
              "0          1.0           85.0   18.0      4.0      NaN          1  \n",
              "1          0.9          135.0   42.0      3.5      NaN          1  \n",
              "2          0.7           96.0   32.0      4.0      NaN          1  \n",
              "3          0.7           46.0   52.0      4.0     80.0          1  \n",
              "4          1.0            NaN  200.0      4.0      NaN          1  \n",
              "..         ...            ...    ...      ...      ...        ...  \n",
              "150        7.6            NaN  242.0      3.3     50.0          2  \n",
              "151        0.9          126.0  142.0      4.3      NaN          2  \n",
              "152        0.8           75.0   20.0      4.1      NaN          2  \n",
              "153        1.5           81.0   19.0      4.1     48.0          2  \n",
              "154        1.2          100.0   19.0      3.1     42.0          2  \n",
              "\n",
              "[155 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aad91e8-5a14-4452-b771-1c1b88acfd52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>AGE</th>\n",
              "      <th>SEX</th>\n",
              "      <th>SETROID</th>\n",
              "      <th>ANTIVIRAL</th>\n",
              "      <th>FATIGUE</th>\n",
              "      <th>MALASIA</th>\n",
              "      <th>ANOREXIA</th>\n",
              "      <th>LIVER BIG</th>\n",
              "      <th>LIVER FIRM</th>\n",
              "      <th>SPLEEN PALPABLE</th>\n",
              "      <th>SPIDERS</th>\n",
              "      <th>ASCITES</th>\n",
              "      <th>VARICES</th>\n",
              "      <th>BILIRUBIN</th>\n",
              "      <th>ALK PHOSPHATE</th>\n",
              "      <th>SGOT</th>\n",
              "      <th>ALBUMIN</th>\n",
              "      <th>PROTIME</th>\n",
              "      <th>HISTOLOGY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>135.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>96.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>46.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>242.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>50.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>126.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>75.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>81.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>48.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>155 rows Ã— 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aad91e8-5a14-4452-b771-1c1b88acfd52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3aad91e8-5a14-4452-b771-1c1b88acfd52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3aad91e8-5a14-4452-b771-1c1b88acfd52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Hp.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ3IZZP374CB",
        "outputId": "267860f4-8c7b-4f8f-8337-91a50984489d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLASS               0\n",
              "AGE                 0\n",
              "SEX                 0\n",
              "SETROID             1\n",
              "ANTIVIRAL           0\n",
              "FATIGUE             1\n",
              "MALASIA             1\n",
              "ANOREXIA            1\n",
              "LIVER BIG          10\n",
              "LIVER FIRM         11\n",
              "SPLEEN PALPABLE     5\n",
              "SPIDERS             5\n",
              "ASCITES             5\n",
              "VARICES             5\n",
              "BILIRUBIN           6\n",
              "ALK PHOSPHATE      29\n",
              "SGOT                4\n",
              "ALBUMIN            16\n",
              "PROTIME            67\n",
              "HISTOLOGY           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_features = [\"AGE\",\"ALK PHOSPHATE\",\t\"SGOT\",\t\"ALBUMIN\"\t,\"PROTIME\"]\n",
        "for column in continuous_features:\n",
        "    Hp[column]=Hp[column].fillna(Hp[column].mean())\n",
        "\n",
        "for column in Hp.columns.drop(continuous_features):\n",
        "    Hp[column]=Hp[column].fillna(Hp[column].mode().sample(1,random_state=1).values[0])"
      ],
      "metadata": {
        "id": "f-zpyLHr8Tvg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Hp.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "yMyqU8jN8jtK",
        "outputId": "4b03871c-0fb9-4dd1-fee7-b54db64c8363"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            CLASS         AGE         SEX     SETROID   ANTIVIRAL     FATIGUE  \\\n",
              "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
              "mean     1.793548   41.200000    1.103226    1.509677    1.845161    1.348387   \n",
              "std      0.406070   12.565878    0.305240    0.501527    0.362923    0.478004   \n",
              "min      1.000000    7.000000    1.000000    1.000000    1.000000    1.000000   \n",
              "25%      2.000000   32.000000    1.000000    1.000000    2.000000    1.000000   \n",
              "50%      2.000000   39.000000    1.000000    2.000000    2.000000    1.000000   \n",
              "75%      2.000000   50.000000    1.000000    2.000000    2.000000    2.000000   \n",
              "max      2.000000   78.000000    2.000000    2.000000    2.000000    2.000000   \n",
              "\n",
              "          MALASIA    ANOREXIA   LIVER BIG  LIVER FIRM  SPLEEN PALPABLE  \\\n",
              "count  155.000000  155.000000  155.000000  155.000000       155.000000   \n",
              "mean     1.606452    1.793548    1.838710    1.612903         1.806452   \n",
              "std      0.490120    0.406070    0.368991    0.488665         0.396360   \n",
              "min      1.000000    1.000000    1.000000    1.000000         1.000000   \n",
              "25%      1.000000    2.000000    2.000000    1.000000         2.000000   \n",
              "50%      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
              "75%      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
              "max      2.000000    2.000000    2.000000    2.000000         2.000000   \n",
              "\n",
              "          SPIDERS     ASCITES     VARICES   BILIRUBIN  ALK PHOSPHATE  \\\n",
              "count  155.000000  155.000000  155.000000  155.000000     155.000000   \n",
              "mean     1.670968    1.870968    1.883871    1.410968     105.325397   \n",
              "std      0.471385    0.336322    0.321418    1.191178      46.405585   \n",
              "min      1.000000    1.000000    1.000000    0.300000      26.000000   \n",
              "25%      1.000000    2.000000    2.000000    0.800000      78.000000   \n",
              "50%      2.000000    2.000000    2.000000    1.000000     102.000000   \n",
              "75%      2.000000    2.000000    2.000000    1.500000     119.500000   \n",
              "max      2.000000    2.000000    2.000000    8.000000     295.000000   \n",
              "\n",
              "             SGOT     ALBUMIN     PROTIME   HISTOLOGY  \n",
              "count  155.000000  155.000000  155.000000  155.000000  \n",
              "mean    85.894040    3.817266   61.852273    1.451613  \n",
              "std     88.478932    0.616750   17.193528    0.499266  \n",
              "min     14.000000    2.100000    0.000000    1.000000  \n",
              "25%     32.500000    3.500000   57.000000    1.000000  \n",
              "50%     59.000000    3.900000   61.852273    1.000000  \n",
              "75%     99.000000    4.200000   65.000000    2.000000  \n",
              "max    648.000000    6.400000  100.000000    2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e605f1d3-fb38-49ea-be16-20e079e0c02d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>AGE</th>\n",
              "      <th>SEX</th>\n",
              "      <th>SETROID</th>\n",
              "      <th>ANTIVIRAL</th>\n",
              "      <th>FATIGUE</th>\n",
              "      <th>MALASIA</th>\n",
              "      <th>ANOREXIA</th>\n",
              "      <th>LIVER BIG</th>\n",
              "      <th>LIVER FIRM</th>\n",
              "      <th>SPLEEN PALPABLE</th>\n",
              "      <th>SPIDERS</th>\n",
              "      <th>ASCITES</th>\n",
              "      <th>VARICES</th>\n",
              "      <th>BILIRUBIN</th>\n",
              "      <th>ALK PHOSPHATE</th>\n",
              "      <th>SGOT</th>\n",
              "      <th>ALBUMIN</th>\n",
              "      <th>PROTIME</th>\n",
              "      <th>HISTOLOGY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>155.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.793548</td>\n",
              "      <td>41.200000</td>\n",
              "      <td>1.103226</td>\n",
              "      <td>1.509677</td>\n",
              "      <td>1.845161</td>\n",
              "      <td>1.348387</td>\n",
              "      <td>1.606452</td>\n",
              "      <td>1.793548</td>\n",
              "      <td>1.838710</td>\n",
              "      <td>1.612903</td>\n",
              "      <td>1.806452</td>\n",
              "      <td>1.670968</td>\n",
              "      <td>1.870968</td>\n",
              "      <td>1.883871</td>\n",
              "      <td>1.410968</td>\n",
              "      <td>105.325397</td>\n",
              "      <td>85.894040</td>\n",
              "      <td>3.817266</td>\n",
              "      <td>61.852273</td>\n",
              "      <td>1.451613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.406070</td>\n",
              "      <td>12.565878</td>\n",
              "      <td>0.305240</td>\n",
              "      <td>0.501527</td>\n",
              "      <td>0.362923</td>\n",
              "      <td>0.478004</td>\n",
              "      <td>0.490120</td>\n",
              "      <td>0.406070</td>\n",
              "      <td>0.368991</td>\n",
              "      <td>0.488665</td>\n",
              "      <td>0.396360</td>\n",
              "      <td>0.471385</td>\n",
              "      <td>0.336322</td>\n",
              "      <td>0.321418</td>\n",
              "      <td>1.191178</td>\n",
              "      <td>46.405585</td>\n",
              "      <td>88.478932</td>\n",
              "      <td>0.616750</td>\n",
              "      <td>17.193528</td>\n",
              "      <td>0.499266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>61.852273</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>119.500000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>295.000000</td>\n",
              "      <td>648.000000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e605f1d3-fb38-49ea-be16-20e079e0c02d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e605f1d3-fb38-49ea-be16-20e079e0c02d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e605f1d3-fb38-49ea-be16-20e079e0c02d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "not_good= Hp['CLASS']<=5\n",
        "is_good= Hp['CLASS']>5\n",
        "print(not_good.value_counts())\n",
        "print(is_good.value_counts())\n",
        "Hp['CLASS'][not_good]=0\n",
        "Hp['CLASS'][is_good]=1\n",
        "Hp['CLASS'].value_counts()\n",
        "print(Hp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu3s3QQv8oSw",
        "outputId": "469e18b1-4cc7-4063-df75-8b8045ddff52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True    155\n",
            "Name: CLASS, dtype: int64\n",
            "False    155\n",
            "Name: CLASS, dtype: int64\n",
            "     CLASS  AGE  SEX  SETROID  ANTIVIRAL  FATIGUE  MALASIA  ANOREXIA  \\\n",
            "0        0   30    2      1.0          2      2.0      2.0       2.0   \n",
            "1        0   50    1      1.0          2      1.0      2.0       2.0   \n",
            "2        0   78    1      2.0          2      1.0      2.0       2.0   \n",
            "3        0   31    1      2.0          1      2.0      2.0       2.0   \n",
            "4        0   34    1      2.0          2      2.0      2.0       2.0   \n",
            "..     ...  ...  ...      ...        ...      ...      ...       ...   \n",
            "150      0   46    1      2.0          2      1.0      1.0       1.0   \n",
            "151      0   44    1      2.0          2      1.0      2.0       2.0   \n",
            "152      0   61    1      1.0          2      1.0      1.0       2.0   \n",
            "153      0   53    2      1.0          2      1.0      2.0       2.0   \n",
            "154      0   43    1      2.0          2      1.0      2.0       2.0   \n",
            "\n",
            "     LIVER BIG  LIVER FIRM  SPLEEN PALPABLE  SPIDERS  ASCITES  VARICES  \\\n",
            "0          1.0         2.0              2.0      2.0      2.0      2.0   \n",
            "1          1.0         2.0              2.0      2.0      2.0      2.0   \n",
            "2          2.0         2.0              2.0      2.0      2.0      2.0   \n",
            "3          2.0         2.0              2.0      2.0      2.0      2.0   \n",
            "4          2.0         2.0              2.0      2.0      2.0      2.0   \n",
            "..         ...         ...              ...      ...      ...      ...   \n",
            "150        2.0         2.0              2.0      1.0      1.0      1.0   \n",
            "151        2.0         1.0              2.0      2.0      2.0      2.0   \n",
            "152        1.0         1.0              2.0      1.0      2.0      2.0   \n",
            "153        2.0         2.0              1.0      1.0      2.0      1.0   \n",
            "154        2.0         2.0              1.0      1.0      1.0      2.0   \n",
            "\n",
            "     BILIRUBIN  ALK PHOSPHATE   SGOT  ALBUMIN    PROTIME  HISTOLOGY  \n",
            "0          1.0      85.000000   18.0      4.0  61.852273          1  \n",
            "1          0.9     135.000000   42.0      3.5  61.852273          1  \n",
            "2          0.7      96.000000   32.0      4.0  61.852273          1  \n",
            "3          0.7      46.000000   52.0      4.0  80.000000          1  \n",
            "4          1.0     105.325397  200.0      4.0  61.852273          1  \n",
            "..         ...            ...    ...      ...        ...        ...  \n",
            "150        7.6     105.325397  242.0      3.3  50.000000          2  \n",
            "151        0.9     126.000000  142.0      4.3  61.852273          2  \n",
            "152        0.8      75.000000   20.0      4.1  61.852273          2  \n",
            "153        1.5      81.000000   19.0      4.1  48.000000          2  \n",
            "154        1.2     100.000000   19.0      3.1  42.000000          2  \n",
            "\n",
            "[155 rows x 20 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= Hp.drop(\"CLASS\", axis=1)\n",
        "y=Hp[\"CLASS\"]\n",
        "x.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpSzmBkl-bgx",
        "outputId": "24e8fb0f-ea15-469d-eed6-eea5120d8cfc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      AGE  SEX  SETROID  ANTIVIRAL  FATIGUE  MALASIA  ANOREXIA  LIVER BIG  \\\n",
              "0     30    2      1.0          2      2.0      2.0       2.0        1.0   \n",
              "1     50    1      1.0          2      1.0      2.0       2.0        1.0   \n",
              "2     78    1      2.0          2      1.0      2.0       2.0        2.0   \n",
              "3     31    1      2.0          1      2.0      2.0       2.0        2.0   \n",
              "4     34    1      2.0          2      2.0      2.0       2.0        2.0   \n",
              "..   ...  ...      ...        ...      ...      ...       ...        ...   \n",
              "150   46    1      2.0          2      1.0      1.0       1.0        2.0   \n",
              "151   44    1      2.0          2      1.0      2.0       2.0        2.0   \n",
              "152   61    1      1.0          2      1.0      1.0       2.0        1.0   \n",
              "153   53    2      1.0          2      1.0      2.0       2.0        2.0   \n",
              "154   43    1      2.0          2      1.0      2.0       2.0        2.0   \n",
              "\n",
              "     LIVER FIRM  SPLEEN PALPABLE  SPIDERS  ASCITES  VARICES  BILIRUBIN  \\\n",
              "0           2.0              2.0      2.0      2.0      2.0        1.0   \n",
              "1           2.0              2.0      2.0      2.0      2.0        0.9   \n",
              "2           2.0              2.0      2.0      2.0      2.0        0.7   \n",
              "3           2.0              2.0      2.0      2.0      2.0        0.7   \n",
              "4           2.0              2.0      2.0      2.0      2.0        1.0   \n",
              "..          ...              ...      ...      ...      ...        ...   \n",
              "150         2.0              2.0      1.0      1.0      1.0        7.6   \n",
              "151         1.0              2.0      2.0      2.0      2.0        0.9   \n",
              "152         1.0              2.0      1.0      2.0      2.0        0.8   \n",
              "153         2.0              1.0      1.0      2.0      1.0        1.5   \n",
              "154         2.0              1.0      1.0      1.0      2.0        1.2   \n",
              "\n",
              "     ALK PHOSPHATE   SGOT  ALBUMIN    PROTIME  HISTOLOGY  \n",
              "0        85.000000   18.0      4.0  61.852273          1  \n",
              "1       135.000000   42.0      3.5  61.852273          1  \n",
              "2        96.000000   32.0      4.0  61.852273          1  \n",
              "3        46.000000   52.0      4.0  80.000000          1  \n",
              "4       105.325397  200.0      4.0  61.852273          1  \n",
              "..             ...    ...      ...        ...        ...  \n",
              "150     105.325397  242.0      3.3  50.000000          2  \n",
              "151     126.000000  142.0      4.3  61.852273          2  \n",
              "152      75.000000   20.0      4.1  61.852273          2  \n",
              "153      81.000000   19.0      4.1  48.000000          2  \n",
              "154     100.000000   19.0      3.1  42.000000          2  \n",
              "\n",
              "[155 rows x 19 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yUdEhqI-nY4",
        "outputId": "a044fae2-0e14-42d3-8024-3800911d9973"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: CLASS, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbY0NNnO-2rR",
        "outputId": "0b3e6282-3dd3-4aa8-8514-4a7e87858472"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81     0\n",
              "142    0\n",
              "31     0\n",
              "29     0\n",
              "118    0\n",
              "60     0\n",
              "93     0\n",
              "147    0\n",
              "153    0\n",
              "68     0\n",
              "42     0\n",
              "138    0\n",
              "78     0\n",
              "75     0\n",
              "15     0\n",
              "19     0\n",
              "30     0\n",
              "90     0\n",
              "117    0\n",
              "137    0\n",
              "18     0\n",
              "12     0\n",
              "9      0\n",
              "24     0\n",
              "69     0\n",
              "131    0\n",
              "95     0\n",
              "45     0\n",
              "86     0\n",
              "84     0\n",
              "126    0\n",
              "Name: CLASS, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# STEP1: Creating the model\n",
        "\n",
        "model= tf.keras.Sequential([\n",
        "                            tf.keras.layers.Dense(10, activation='relu'),\n",
        "                            tf.keras.layers.Dense(7, activation='relu'),\n",
        "                            tf.keras.layers.Dense(5, activation='relu'),\n",
        "                            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# STEP2: Compiling the model\n",
        "\n",
        "model.compile(loss= tf.keras.losses.binary_crossentropy,\n",
        "              optimizer= tf.keras.optimizers.Adam(lr=0.005),\n",
        "              metrics= [tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                        tf.keras.metrics.Precision(name='precision'),\n",
        "                        tf.keras.metrics.Recall(name='a=recall')\n",
        "              ]\n",
        "              )\n",
        "\n",
        "# STEP1: Fit the model\n",
        "\n",
        "history= model.fit(x_train, y_train, epochs= 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATH8cQ3H_FWJ",
        "outputId": "4c616737-0140-4737-abbb-df2607df38be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 1.3462 - accuracy: 0.8548 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9919 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.8876e-04 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2990e-04 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 7.3636e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.6895e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.6388e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2084e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.9469e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5066e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3088e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2077e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1850e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0963e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0625e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0225e-05 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 9.9685e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.7510e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.5291e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.4731e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.1769e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.1174e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.9095e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.7475e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 8.5735e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.4593e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.3026e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.1115e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.9772e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.8379e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.7852e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.5187e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.4350e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.2285e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.1141e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.9498e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.8632e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.6584e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.5287e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.4503e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.2449e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.1408e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.0329e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.8525e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.8102e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.6393e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.5370e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.4123e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.2930e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.1217e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.0428e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.9188e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.8590e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.7462e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.6165e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.5426e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4390e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.3429e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.2452e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.1402e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.0905e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.9606e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.8840e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.7899e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.7127e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.6820e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.5879e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.4589e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.4019e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.3265e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.2694e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.1820e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.1404e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.0667e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.9854e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.9134e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.8785e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.8131e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.7530e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.6826e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.6292e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.5593e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.5113e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.4815e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.4153e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3556e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3391e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2552e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2190e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.1823e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.1254e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0749e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.0520e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.0058e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.9566e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.9120e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8911e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.8504e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.8196e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.7672e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.7489e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.7131e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6779e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6346e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.6188e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.5863e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5414e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.5216e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4941e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4724e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.4415e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.4296e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.4038e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3785e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.3688e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3455e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3275e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.3072e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2908e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2735e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.2558e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.2382e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2279e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2124e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.1866e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1687e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1536e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1388e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.1298e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1096e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0920e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0781e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0696e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0539e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0344e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0240e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0157e-06 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.9389e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.8979e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.7247e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.5780e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.5129e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.3381e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.2108e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.1760e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 9.0179e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.9067e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.7777e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.6968e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.5538e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.4778e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.3918e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.2876e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 8.1830e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.1044e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.9989e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.8657e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.8154e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.7200e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.6252e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.5350e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.4496e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.3315e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.2710e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 7.1906e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.1234e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.0247e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.9462e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.8431e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.8039e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.7207e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.6279e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.5697e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.4692e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.4140e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.3555e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.2650e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.1978e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.1604e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.0818e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.9981e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.9213e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.8741e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.8229e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.7317e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6980e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.6096e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.5664e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.5187e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.4440e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.4003e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.3396e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.2531e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.2371e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 5.1755e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.0886e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.0723e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.9826e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.9549e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.9106e-07 - accuracy: 1.0000 - precision: 0.0000e+00 - a=recall: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "lumeTIIae4fR",
        "outputId": "02de2d70-bf91-4bb2-e9a5-a39fa410411e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb795295450>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EPVTA20kinNL"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}